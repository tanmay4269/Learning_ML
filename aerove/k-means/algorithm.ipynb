{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Means practice\n",
    "\n",
    "Gotta apply k means on the dataset and find out clusters of people depending on various features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'Gender', 'Ever_Married', 'Age', 'Graduated', 'Profession',\n",
      "       'Work_Experience', 'Spending_Score', 'Family_Size', 'Var_1',\n",
      "       'Segmentation'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# Importing data\n",
    "raw_train_df = pd.read_csv(\"data/train.csv\")\n",
    "raw_test_df = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "print(raw_train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: [462809 462643 466315 ... 465406 467299 461879]\n",
      "Gender: ['Male' 'Female']\n",
      "Ever_Married: ['No' 'Yes' nan]\n",
      "Age: [22 38 67 40 56 32 33 61 55 26 19 70 58 41 31 79 49 18 36 35 45 42 83 27\n",
      " 28 47 29 57 76 25 72 48 74 59 39 51 30 63 52 60 68 86 50 43 80 37 46 69\n",
      " 78 71 82 23 20 85 21 53 62 75 65 89 66 73 77 87 84 81 88]\n",
      "Graduated: ['No' 'Yes' nan]\n",
      "Profession: ['Healthcare' 'Engineer' 'Lawyer' 'Entertainment' 'Artist' 'Executive'\n",
      " 'Doctor' 'Homemaker' 'Marketing' nan]\n",
      "Work_Experience: [ 1. nan  0.  4.  9. 12.  3. 13.  5.  8. 14.  7.  2.  6. 10. 11.]\n",
      "Spending_Score: ['Low' 'Average' 'High']\n",
      "Family_Size: [ 4.  3.  1.  2.  6. nan  5.  8.  7.  9.]\n",
      "Var_1: ['Cat_4' 'Cat_6' 'Cat_7' 'Cat_3' 'Cat_1' 'Cat_2' nan 'Cat_5']\n",
      "Segmentation: ['D' 'A' 'B' 'C']\n"
     ]
    }
   ],
   "source": [
    "for column in raw_train_df.columns:\n",
    "    print(f\"{column}: {pd.unique(raw_train_df[column])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: [462809 466315 461735 ... 465406 467299 461879]\n",
      "Gender: ['Male' 'Female']\n",
      "Ever_Married: ['No' 'Yes']\n",
      "Age: [22 67 56 32 33 61 55 26 19 58 41 31 79 49 18 36 35 45 42 83 27 28 47 40\n",
      " 57 76 25 48 74 59 51 30 63 52 39 38 60 68 86 43 80 37 46 72 69 50 29 71\n",
      " 78 82 70 23 20 21 53 75 65 89 62 66 73 77 87 84 88 85 81]\n",
      "Graduated: ['No' 'Yes']\n",
      "Profession: ['Healthcare' 'Engineer' 'Lawyer' 'Artist' 'Doctor' 'Homemaker'\n",
      " 'Entertainment' 'Marketing' 'Executive']\n",
      "Work_Experience: [ 1.  0.  4.  9. 12.  3. 13.  5.  8. 14.  7.  2.  6. 10. 11.]\n",
      "Spending_Score: ['Low' 'High' 'Average']\n",
      "Family_Size: [4. 1. 2. 3. 5. 6. 8. 7. 9.]\n",
      "Var_1: ['Cat_4' 'Cat_6' 'Cat_7' 'Cat_3' 'Cat_1' 'Cat_2' 'Cat_5']\n",
      "Segmentation: ['D' 'B' 'C' 'A']\n"
     ]
    }
   ],
   "source": [
    "# eliminating all rows with atleast one \"nan\" entry\n",
    "raw_train_df = raw_train_df.dropna()\n",
    "raw_test_df = raw_test_df.dropna()\n",
    "\n",
    "for column in raw_train_df.columns:\n",
    "    print(f\"{column}: {pd.unique(raw_train_df[column])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = test and train  *ONLY*\n",
    "def init_df(X):\n",
    "    # Removing \"Var_1, Segmentation\"\n",
    "    X.drop(\"ID\", axis=1, inplace=True)\n",
    "    X.drop(\"Var_1\", axis=1, inplace=True)\n",
    "    X.drop(\"Segmentation\", axis=1, inplace=True)\n",
    "\n",
    "    # Gender\n",
    "    X.loc[X[\"Gender\"] == \"Male\", \"Gender\"] = 0\n",
    "    X.loc[X[\"Gender\"] == \"Female\", \"Gender\"] = 1\n",
    "\n",
    "    # Ever_Married\n",
    "    X.loc[X[\"Ever_Married\"] == \"No\", \"Ever_Married\"] = 0\n",
    "    X.loc[X[\"Ever_Married\"] == \"Yes\", \"Ever_Married\"] = 1\n",
    "\n",
    "    # Age\n",
    "    age_mean = np.mean(X[\"Age\"])\n",
    "    age_std_deviation = np.std(X[\"Age\"])\n",
    "\n",
    "    X[\"Age\"] = (X[\"Age\"] - age_mean) / age_std_deviation\n",
    "\n",
    "    # Graduated\n",
    "    X.loc[X[\"Graduated\"] == \"No\", \"Graduated\"] = 0\n",
    "    X.loc[X[\"Graduated\"] == \"Yes\", \"Graduated\"] = 1\n",
    "\n",
    "    # Profession - One-hot encoding\n",
    "    encoded_profession = pd.get_dummies(X[\"Profession\"]).astype(int)  # .get_dummies does one-hot encoding\n",
    "    X = pd.concat([X, encoded_profession], axis=1)\n",
    "    X.drop(\"Profession\", axis=1, inplace=True)\n",
    "\n",
    "    # Work experence\n",
    "    work_mean = np.mean(X[\"Work_Experience\"])\n",
    "    work_std_deviation = np.std(X[\"Work_Experience\"])\n",
    "\n",
    "    X[\"Work_Experience\"] = (X[\"Work_Experience\"] - work_mean) / work_std_deviation\n",
    "\n",
    "    # Spending score\n",
    "    X.loc[X[\"Spending_Score\"] == \"Low\", \"Spending_Score\"] = 0\n",
    "    X.loc[X[\"Spending_Score\"] == \"Average\", \"Spending_Score\"] = 0.5\n",
    "    X.loc[X[\"Spending_Score\"] == \"High\", \"Spending_Score\"] = 1\n",
    "\n",
    "    # Family_Size\n",
    "    fam_mean = np.mean(X[\"Family_Size\"])\n",
    "    fam_std_deviation = np.std(X[\"Family_Size\"])\n",
    "\n",
    "    X[\"Family_Size\"] = (X[\"Family_Size\"] - fam_mean) / fam_std_deviation\n",
    "\n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_clusters(X, clusters, cluster_centroids):\n",
    "    for pt_i in range(X.shape[0]):\n",
    "        distances = []\n",
    "        for cluster_i in range(len(clusters)):\n",
    "            distance_vector = cluster_centroids[cluster_i, :] - X[pt_i, :]\n",
    "            distance = np.linalg.norm(distance_vector)\n",
    "            distances.append(distance)\n",
    "        \n",
    "        nearest_cluster_i = distances.index(min(distances))\n",
    "        clusters[nearest_cluster_i].append(X[pt_i, :])\n",
    "\n",
    "\n",
    "def update_centroids(X, clusters, cluster_centroids):\n",
    "    n_features = X.shape[1]\n",
    "    for cluster_i in range(cluster_centroids.shape[0]):\n",
    "        x = np.array(clusters[cluster_i]).reshape(len(clusters[cluster_i]), n_features)\n",
    "        x_mean = np.mean(x, axis=0).reshape(1, -1)\n",
    "\n",
    "        # Update centroids\n",
    "        cluster_centroids[cluster_i, :] = x_mean\n",
    "\n",
    "\n",
    "def compute_cost(X, clusters, cluster_centroids):\n",
    "    n_clusters = len(clusters)\n",
    "    n_samples = X.shape[0]\n",
    "    distances = np.zeros((n_samples, n_clusters))\n",
    "\n",
    "    for cluster_i in range(n_clusters):\n",
    "        centroid = cluster_centroids[cluster_i]\n",
    "        distance_vectors = X - centroid\n",
    "        distances[:, cluster_i] = np.linalg.norm(distance_vectors)\n",
    "\n",
    "    cost = np.sum(distances)\n",
    "\n",
    "    return cost\n",
    "\n",
    "# def update_clusters(X, clusters, cluster_centroids):\n",
    "#     for pt_i in range(X.shape[0]):\n",
    "#         distances = []\n",
    "#         for cluster_i in range(len(clusters)):\n",
    "#             distance_vector = cluster_centroids[cluster_i, :] - X[pt_i, :]\n",
    "#             distance = np.linalg.norm(distance_vector)\n",
    "#             distances.append(distance)\n",
    "        \n",
    "#         nearest_cluster_i = distances.index(min(distances))\n",
    "#         clusters[nearest_cluster_i].append(X[pt_i, :])\n",
    "\n",
    "\n",
    "# def update_centroids(X, clusters, cluster_centroids):\n",
    "#     for cluster_i in range(len(clusters)):\n",
    "#         if len(clusters[cluster_i]) > 0:\n",
    "#             x = np.array(clusters[cluster_i])\n",
    "#             x_mean = np.mean(x, axis=0)\n",
    "#             cluster_centroids[cluster_i] = x_mean\n",
    "\n",
    "\n",
    "# def compute_cost(X, clusters, cluster_centroids):\n",
    "#     cost = 0\n",
    "#     for cluster_i, cluster in enumerate(clusters):\n",
    "#         if len(cluster) > 0:\n",
    "#             cluster_data = X[np.array(cluster, dtype=np.int64)]  # Convert the list of indices to an integer NumPy array\n",
    "#             distance = np.linalg.norm(cluster_data - cluster_centroids[cluster_i])\n",
    "#             cost += distance\n",
    "\n",
    "#     return cost\n",
    "\n",
    "\n",
    "def clusterize(X, n_centroids):\n",
    "    n_features = X.shape[1]\n",
    "    cluster_centroids = np.random.uniform(-0.1, 0.1, (n_centroids, n_features))\n",
    "    clusters = [[] for _ in range(n_centroids)]\n",
    "\n",
    "    costs = []\n",
    "    iterations = 100\n",
    "    for _ in range(iterations):\n",
    "        # Step 1: Assign each \"person\" its centroid\n",
    "        update_clusters(X, clusters, cluster_centroids)\n",
    "\n",
    "        # Step 2: Find center of each cluster\n",
    "        update_centroids(X, clusters, cluster_centroids)\n",
    "\n",
    "        cost = compute_cost(X, clusters, cluster_centroids)\n",
    "        costs.append(cost)\n",
    "\n",
    "    return clusters, cluster_centroids, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m n_clusters \u001b[39m=\u001b[39m \u001b[39m4\u001b[39m\n\u001b[0;32m      9\u001b[0m costs \u001b[39m=\u001b[39m []\n\u001b[1;32m---> 10\u001b[0m clusters, cluster_centroids, costs \u001b[39m=\u001b[39m clusterize(X_train, n_clusters)\n\u001b[0;32m     12\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39mlen\u001b[39m(costs))\n\u001b[0;32m     13\u001b[0m plt\u001b[39m.\u001b[39mplot(x, costs)\n",
      "Cell \u001b[1;32mIn[35], line 82\u001b[0m, in \u001b[0;36mclusterize\u001b[1;34m(X, n_centroids)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[39m# Step 2: Find center of each cluster\u001b[39;00m\n\u001b[0;32m     80\u001b[0m     update_centroids(X, clusters, cluster_centroids)\n\u001b[1;32m---> 82\u001b[0m     cost \u001b[39m=\u001b[39m compute_cost(X, clusters, cluster_centroids)\n\u001b[0;32m     83\u001b[0m     costs\u001b[39m.\u001b[39mappend(cost)\n\u001b[0;32m     85\u001b[0m \u001b[39mreturn\u001b[39;00m clusters, cluster_centroids, costs\n",
      "Cell \u001b[1;32mIn[35], line 62\u001b[0m, in \u001b[0;36mcompute_cost\u001b[1;34m(X, clusters, cluster_centroids)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(cluster) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     61\u001b[0m         cluster_data \u001b[39m=\u001b[39m X[np\u001b[39m.\u001b[39marray(cluster, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint64)]  \u001b[39m# Convert the list of indices to an integer NumPy array\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m         distance \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49mnorm(cluster_data \u001b[39m-\u001b[39;49m cluster_centroids[cluster_i])\n\u001b[0;32m     63\u001b[0m         cost \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m distance\n\u001b[0;32m     65\u001b[0m \u001b[39mreturn\u001b[39;00m cost\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mnorm\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\linalg\\linalg.py:2527\u001b[0m, in \u001b[0;36mnorm\u001b[1;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[0;32m   2525\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2526\u001b[0m     sqnorm \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mdot(x)\n\u001b[1;32m-> 2527\u001b[0m ret \u001b[39m=\u001b[39m sqrt(sqnorm)\n\u001b[0;32m   2528\u001b[0m \u001b[39mif\u001b[39;00m keepdims:\n\u001b[0;32m   2529\u001b[0m     ret \u001b[39m=\u001b[39m ret\u001b[39m.\u001b[39mreshape(ndim\u001b[39m*\u001b[39m[\u001b[39m1\u001b[39m])\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    X_train = raw_train_df.copy()\n",
    "    X_test = raw_test_df.copy()\n",
    "\n",
    "    X_train = init_df(X_train)\n",
    "    X_test = init_df(X_test)\n",
    "\n",
    "    n_clusters = 4\n",
    "    costs = []\n",
    "    clusters, cluster_centroids, costs = clusterize(X_train, n_clusters)\n",
    "\n",
    "    x = np.arange(len(costs))\n",
    "    plt.plot(x, costs)\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
